{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변 후보자는 허인회씨가 이사장으로 있던 태양광 업체 녹색드림협동조합과의 유착 의혹을 부인했다. 녹색드림협동조합은 2015년 서울주택도시공사(SH)에 태양광 미니발전소 25건을 기부한 뒤, 2016년 서울시 전체 태양광 미니발전소 보급 업체로 선정됐다. 이에 대해 야권은 ▶협약 체결 당시 기준, 녹색드림협동조합은 태양광 보급 실적이 한 건도 없었고 ▶다른 태양광 보급 업체와 맺은 협약은 언론에 공개하고 녹색드림협동조합과의 협약은 공개하지 않았다는 점을 문제 삼았다. \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://news.v.daum.net/v/20201219191528518')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "mydata = soup.find(\"p\",attrs={'dmcf-pid':'AnH41D3T2k','dmcf-ptype':'general'})\n",
    "\n",
    "print(mydata.get_text())\n",
    "\n",
    "# for item in mydata:\n",
    "#     print(item.get_text())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 후처리\n",
    "* \\n , 불필요한 데이터 삭제, 깔끔하게 문자열 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 크롤링과 강력한 크롤링 기술 팁1(2020 업데이트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "titles = soup.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 강사가 실제 사용하는 자동 프로그램 소개 \n",
      " 필요한 프로그램 설치 시연 \n",
      " 데이터를 엑셀 파일로 만들기 \n",
      "     엑셀 파일 이쁘게! 이쁘게! \n",
      "     나대신 주기적으로 파이썬 프로그램 실행하기 \n",
      " 파이썬으로 슬랙(slack) 메신저에 글쓰기 \n",
      " 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 \n",
      " 네이버 API 사용해서, 블로그에 글쓰기 \n",
      " 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 \n"
     ]
    }
   ],
   "source": [
    "# split 사용해서 리스트로 구분한 후 필요없는 것 빼버리기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text().split('-')[1].split('[')[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강사가 실제 사용하는 자동 프로그램 소개\n",
      "필요한 프로그램 설치 시연\n",
      "데이터를 엑셀 파일로 만들기\n",
      "엑셀 파일 이쁘게! 이쁘게!\n",
      "나대신 주기적으로 파이썬 프로그램 실행하기\n",
      "파이썬으로 슬랙(slack) 메신저에 글쓰기\n",
      "웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기\n",
      "네이버 API 사용해서, 블로그에 글쓰기\n",
      "자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기\n"
     ]
    }
   ],
   "source": [
    "# 공백 앞으로 땡기기(strip())\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text().split('-')[1].split('[')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 강사가 실제 사용하는 자동 프로그램 소개\n",
      "2. 필요한 프로그램 설치 시연\n",
      "3. 데이터를 엑셀 파일로 만들기\n",
      "4. 엑셀 파일 이쁘게! 이쁘게!\n",
      "5. 나대신 주기적으로 파이썬 프로그램 실행하기\n",
      "6. 파이썬으로 슬랙(slack) 메신저에 글쓰기\n",
      "7. 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기\n",
      "8. 네이버 API 사용해서, 블로그에 글쓰기\n",
      "9. 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기\n"
     ]
    }
   ],
   "source": [
    "# 인덱스 붙이기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for index, title in enumerate(titles):\n",
    "    print(str(index+1)+'.',title.get_text().split('-')[1].split('[')[0].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS selector 사용해서 크롤링하기1(2020 업데이트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test_css.html')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "items = soup.select('ul a')  # css 에서는 find 대신 select 를 써준다\n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test_css.html')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "items = soup.select('.course')  # class 는 . , id는 #으로 표기\n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test_css.html')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "items = soup.select('ul#hobby_course_list li.course')  \n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test_css.html')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "items = soup.select('ul#dev_course_list > li.course.paid')  \n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test_css.html')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "items = soup.select('a.keyword span.txt ')  \n",
    "for item in items:\n",
    "    print(item.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "# select_one 사용\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test_css.html')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "items = soup.select_one('ul#dev_course_list > li.course.paid')  \n",
    "print(items.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일정, 커리큘럼 타이틀, 난이도\n",
      "5.1 ~ 6.15, 나만의 엣지있는 블로그 사이트 만들기 (취미로 익히는 IT), 초급\n",
      "6.16 ~ 7.31, 파이썬과 데이터과학 첫걸음 (IT 기본기 익히기), 중급\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_html_css.html')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "items = soup.find_all('tr')  \n",
    "for item in items:\n",
    "    columns = item.select('td')\n",
    "    row_str=''\n",
    "    for column in columns:\n",
    "        row_str += ', '+column.get_text()\n",
    "    print(row_str[2:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
